import json
import re
import ipaddress
from typing import Dict, Any

# --- 1. å®šæ•°å¤‰æ›ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•° ---

# SymNetã§ã¯ã€Z3ã®Intå‹ã®ç¯„å›²åˆ¶é™ï¼ˆ-2^31 ~ 2^31-1ï¼‰ã«å¯¾å¿œã™ã‚‹ãŸã‚ã€
# IPã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’æ ¼ç´ã™ã‚‹éš›ã«2^31ã‚’å¼•ã„ã¦ã„ã‚‹
IP_OFFSET = 2147483648  # 2^31

def int_to_mac(val: int) -> str | None:
    if not (0 <= val <= 281474976710655):
        return None
    hex_str = f'{val:012x}'
    return ':'.join(hex_str[i:i+2] for i in (0, 2, 4, 6, 8, 10))

def int_to_ip(val: int) -> str | None:
    # SymNetã‹ã‚‰æ¥ãŸå€¤ã¯2^31å¼•ã‹ã‚Œã¦ã„ã‚‹ã®ã§ã€å…ƒã«æˆ»ã™
    unsigned_val = val + IP_OFFSET
    
    if not (0 <= unsigned_val <= 4294967295):
        return None
    return str(ipaddress.IPv4Address(unsigned_val))

def format_constant(val_str: str, context_field_name: str | None = None) -> str:
    try:
        val = int(val_str)
    except ValueError:
        return val_str

    if val == 2048: return "IPv4 (0x0800)"
    if val == 2054: return "ARP (0x0806)"
    if val == 34525: return "VLAN (0x8100)"

    if context_field_name:
        if context_field_name.startswith("IP"):
            if (ip_val := int_to_ip(val)):
                return f"{ip_val} (IP)"
            else:
                # IPãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã ãŒç¯„å›²å¤–ã®å€¤
                return f"Val: {val} (0x{val:x})"
        elif context_field_name.startswith("Eth"):
            if (mac_val := int_to_mac(val)):
                return f"{mac_val} (MAC)"
            else:
                # MACãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã ãŒç¯„å›²å¤–ã®å€¤
                return f"Val: {val} (0x{val:x})"
        elif context_field_name.endswith("Port"):
            if 0 <= val <= 65535:
                if val == 80: return "80 (Port: HTTP)"
                if val == 443: return "443 (Port: HTTPS)"
                if val == 22: return "22 (Port: SSH)"
                if val == 53: return "53 (Port: DNS)"
                return f"{val} (Port)"
            else:
                # ãƒãƒ¼ãƒˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã ãŒç¯„å›²å¤–ã®å€¤
                return f"Val: {val} (0x{val:x})"

    possible_formats = []
    ip_val = int_to_ip(val)
    mac_val = int_to_mac(val)

    if ip_val:
        possible_formats.append(f"IP: {ip_val}")
    if mac_val:
        possible_formats.append(f"MAC: {mac_val}")

    raw_str = ""
    if val == 80: raw_str = "80 (Port: HTTP)"
    elif val == 443: raw_str = "443 (Port: HTTPS)"
    elif val == 22: raw_str = "22 (Port: SSH)"
    elif val == 53: raw_str = "53 (Port: DNS)"
    elif 0 <= val <= 65535:
        raw_str = f"Val: {val}"
    else:
        raw_str = f"Val: {val} (0x{val:x})"

    if not ip_val and not mac_val:
        return raw_str
    
    possible_formats.append(raw_str)
    return " / ".join(possible_formats)


# --- 2. ãƒ¡ã‚¤ãƒ³ã®ãƒ‘ãƒ¼ã‚µã‚¯ãƒ©ã‚¹ (to_markdown ã‚’ä¿®æ­£) ---

class SymNetParser:
    
    KNOWN_OFFSETS = {
        'L2': { 
            0: 'EthDst', 
            48: 'EthSrc', 
            96: 'EtherType',
            112: 'VLAN_PCP',      # Priority Code Point (3 bits)
            115: 'VLAN_DEI',      # Drop Eligible Indicator (1 bit)
            116: 'VLAN_VID'       # VLAN Identifier (12 bits)
        },
        'L3': { 0: 'IPVer_IHL', 4: 'DSCP_ECN', 16: 'TotalLength', 32: 'Identification', 64: 'TTL', 72: 'IPProto', 80: 'IPChecksum', 96: 'IPSrc', 128: 'IPDst' },
        'L4': { 0: 'SrcPort', 16: 'DstPort', 32: 'SeqNo', 64: 'AckNo', 96: 'DataOffset', 107: 'Flag_NS', 108: 'Flag_CWR', 109: 'Flag_ECE', 110: 'Flag_URG', 111: 'Flag_ACK', 112: 'Flag_PSH', 113: 'Flag_RST', 114: 'Flag_SYN', 115: 'Flag_FIN' }
    }
    
    # ( __init__ ã¯å¤‰æ›´ãªã—)
    def __init__(self, json_data: Dict[str, Any]):
        self.data = json_data
        self.tags = {}
        self.abs_field_map = {}
        self.string_field_map = {}

        for tag_obj in self.data.get('memory', {}).get('tags', []):
            name, offset = list(tag_obj.items())[0]
            self.tags[name] = offset

        for tag_name, base_offset in self.tags.items():
            if tag_name in self.KNOWN_OFFSETS:
                for rel_offset, field_name in self.KNOWN_OFFSETS[tag_name].items():
                    self.string_field_map[f"{tag_name}+{rel_offset}"] = field_name
                    self.abs_field_map[base_offset + rel_offset] = field_name
    
    def _parse_port_name(self, port_name: str) -> tuple[str, str]:
        """ãƒãƒ¼ãƒˆåã‹ã‚‰ãƒãƒ¼ãƒ‰åã¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åã‚’æŠ½å‡ºã™ã‚‹"""
        # ãƒãƒ¼ãƒˆåã®å½¢å¼: <ãƒãƒ¼ãƒ‰>-<ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«>-<æ–¹å‘>
        # ä¾‹: host1-host-in, ap-wifi1_i-in, rtx1210-lan1_i-in
        parts = port_name.split('-', 1)  # æœ€åˆã® '-' ã§åˆ†å‰²
        if len(parts) == 2:
            node = parts[0]
            # æ®‹ã‚Šã®éƒ¨åˆ†ã‹ã‚‰æ–¹å‘ ("-in", "-out") ã‚’é™¤å»
            module_part = parts[1]
            if module_part.endswith('-in'):
                module = module_part[:-3]
            elif module_part.endswith('-out'):
                module = module_part[:-4]
            else:
                module = module_part
            return (node, module)
        return (port_name, '')
    
    def _format_constraint(self, constraint: str) -> str:
        """åˆ¶ç´„ã‚’èª­ã¿ã‚„ã™ãæ•´å½¢ã™ã‚‹"""
        # ~(&(List(...))) ã®ã‚ˆã†ãªå¦å®šåˆ¶ç´„ã‚’æ¤œå‡º
        if constraint.startswith('~(&(List('):
            # å¦å®šåˆ¶ç´„ã‚’æŠ½å‡º
            inner = constraint[9:-3]  # "~(&(List(" ã¨ ")))" ã‚’å‰Šé™¤
            parts = inner.split('), ')
            if len(parts) == 2:
                # [Const(...)] ã®éƒ¨åˆ†ã‚’æŠ½å‡º
                min_part = parts[0].split('[Const(')[1].split(')]')[0]
                max_part = parts[1].split('[Const(')[1].split(')]')[0]
                return f"NOT IN [{min_part} - {max_part}]"
        
        # &(List(...)) ã®ã‚ˆã†ãªç¯„å›²åˆ¶ç´„ã‚’æ¤œå‡º
        elif constraint.startswith('&(List('):
            inner = constraint[7:-2]  # "&(List(" ã¨ "))" ã‚’å‰Šé™¤
            parts = inner.split('), ')
            if len(parts) == 2:
                # [Const(...)] ã®éƒ¨åˆ†ã‚’æŠ½å‡º
                min_part = parts[0].split('[Const(')[1].split(')]')[0]
                max_part = parts[1].split('[Const(')[1].split(')]')[0]
                return f"IN [{min_part} - {max_part}]"
        
        # ==(...) ã®ã‚ˆã†ãªç­‰ä¾¡åˆ¶ç´„
        elif constraint.startswith('==([Const('):
            value = constraint.split('[Const(')[1].split(')]')[0]
            return f"== {value}"
        
        return constraint

    # ( _translate_string ã¯å¤‰æ›´ãªã—)
    def _translate_string(self, s: str, context_field_name: str | None = None) -> str:
        if not isinstance(s, str):
            return str(s)

        inferred_context = context_field_name
        if inferred_context is None:
            for key, name in self.string_field_map.items():
                if key in s:
                    inferred_context = name
                    break 

        s = re.sub(
            r'\[Const\((\d+)\)\]',
            lambda m: f"[Const({format_constant(m.group(1), inferred_context)})]",
            s
        )
        
        sorted_keys = sorted(self.string_field_map.keys(), key=len, reverse=True)
        for key in sorted_keys:
            s = s.replace(key, self.string_field_map[key])
        
        return s

    def to_markdown(self) -> str:
        """è§£æçµæœã‚’äººé–“å¯èª­ãªMarkdownæ–‡å­—åˆ—ã¨ã—ã¦ç”Ÿæˆã™ã‚‹"""
        md_lines = []
        md_lines.append("# SymNet è§£æãƒ¬ãƒãƒ¼ãƒˆ\n") # ã“ã®è¦‹å‡ºã—ã¯å¾Œã§ç½®æ›ã•ã‚Œã¾ã™

        # --- 1. Status ---
        md_lines.append("## ğŸš¦ 1. æœ€çµ‚ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ (Status)")
        md_lines.append("```")
        md_lines.append(self._translate_string(self.data['status']))
        md_lines.append("```")
        md_lines.append("\n")

        # --- 2. Port Trace ---
        md_lines.append("## ğŸ—ºï¸ 2. ãƒ‘ã‚±ãƒƒãƒˆã®çµŒè·¯ (Port Trace)")
        
        # ãƒãƒ¼ãƒˆæƒ…å ±ã‚’ä¸€åº¦ã ã‘èª­ã¿å–ã‚‹
        port_map = {}
        path_ports = []
        for item in self.data['port_trace']:
            idx_str, port_name = list(item.items())[0]
            port_map[int(idx_str)] = port_name
            path_ports.append(port_name)
        
        # ãƒãƒ¼ãƒ‰ãŒå¤‰ã‚ã£ãŸã‚‰æ”¹è¡Œã‚’å…¥ã‚Œã‚‹
        path_lines = []
        current_line = []
        prev_node = None
        
        for port in path_ports:
            node, _ = self._parse_port_name(port)
            
            if prev_node is not None and node != prev_node:
                # ãƒãƒ¼ãƒ‰ãŒå¤‰ã‚ã£ãŸã®ã§ã€ç¾åœ¨ã®è¡Œã‚’ä¿å­˜ã—ã¦æ–°ã—ã„è¡Œã‚’é–‹å§‹
                path_lines.append(" -> ".join(f"`{p}`" for p in current_line))
                current_line = [port]
            else:
                current_line.append(port)
            
            prev_node = node
        
        # æœ€å¾Œã®è¡Œã‚’è¿½åŠ 
        if current_line:
            path_lines.append(" -> ".join(f"`{p}`" for p in current_line))
        
        md_lines.append("**Path:**")
        for line in path_lines:
            md_lines.append(f"{line}  ")
        md_lines.append("\n")

        # --- 3. Instruction Trace ---
        md_lines.append("## ğŸ“œ 3. å®Ÿè¡Œã•ã‚ŒãŸå‘½ä»¤ (Instruction Trace)")
        
        for i, item in enumerate(self.data['instruction_trace']):
            idx_str, instruction = list(item.items())[0]
            
            # NoOpå‘½ä»¤ã‚’ç°¡ç•¥åŒ–
            if instruction.startswith('org.change.v2.analysis.processingmodels.instructions.NoOp'):
                instruction = 'NoOp'
            
            is_forward = instruction.startswith('Forward(')
            
            md_lines.append(f"- `{self._translate_string(instruction)}`")
            
            # Forwardå‘½ä»¤ã®ã‚ã¨ã«åŒºåˆ‡ã‚Šç·šã‚’è¿½åŠ ï¼ˆæœ€å¾Œã®Forwardã‚’é™¤ãï¼‰
            if is_forward and i < len(self.data['instruction_trace']) - 1:
                md_lines.append("")
                md_lines.append("---")
                md_lines.append("")
        
        md_lines.append("\n")

        # --- 4. Memory State ---
        md_lines.append("## ğŸ§  4. æœ€çµ‚çš„ãªãƒ‘ã‚±ãƒƒãƒˆã®ãƒ¡ãƒ¢ãƒªçŠ¶æ…‹ (Final Memory State)")
        
        md_lines.append("### ã‚¿ã‚° (Tags)")
        tags_str = ", ".join([f"`{name}: {offset}`" for name, offset in self.tags.items()])
        md_lines.append(tags_str)
        md_lines.append("\n")
        
        md_lines.append("### ãƒ˜ãƒƒãƒ€ãƒ¼ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ (Header Fields)")
        
        fields = []
        for item in self.data['memory']['header_fields']:
            offset_str, data = item.popitem()
            fields.append((int(offset_str), data))
        fields.sort(key=lambda x: x[0])
        
        for offset, data in fields:
            field_name = self.abs_field_map.get(offset, f"Unknown (Offset {offset})")
            
            expr = self._translate_string(data['expression'], field_name)
            constraints = [self._translate_string(c, field_name) for c in data['constraints']]
            
            md_lines.append(f"\n#### `[{field_name}]` (AbsOffset: {offset})")
            md_lines.append("```")
            md_lines.append(f"Value: {expr}")
            if constraints:
                md_lines.append("Constraints:")
                for c in constraints:
                    formatted = self._format_constraint(c)
                    md_lines.append(f"  - {formatted}")
            md_lines.append("```")

        return "\n".join(md_lines)

# --- 3. å®Ÿè¡Œ ---
if __name__ == "__main__":
    input_json_files = [
        ('sefl.ok.json', 'âœ… OK'),
        ('sefl.fail.json', 'âŒ FAIL')
    ]
    
    all_markdown_reports = [] 
    ok_count = 0
    fail_count = 0
    fail_statuses = []

    for input_json_file, status_label in input_json_files:
        try:
            with open(input_json_file, 'r') as f:
                data_list = json.load(f) 
                
            if not isinstance(data_list, list):
                if isinstance(data_list, dict):
                    data_list = [data_list]
                else:
                    print(f"ã‚¨ãƒ©ãƒ¼: {input_json_file} ã®å½¢å¼ãŒä¸æ­£ã§ã™ã€‚")
                    continue

            if not data_list:
                print(f"è­¦å‘Š: {input_json_file} ãŒç©ºã§ã™ã€‚")
                continue

            for data_item in data_list:
                if not isinstance(data_item, dict):
                    print(f"è­¦å‘Š: {input_json_file} å†…ã®ä¸€éƒ¨ã®ã‚¢ã‚¤ãƒ†ãƒ ãŒJSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                    continue
                    
                parser = SymNetParser(data_item)
                markdown_output = parser.to_markdown()
                all_markdown_reports.append((markdown_output, status_label))
                
                # OK/FAILã®ã‚«ã‚¦ãƒ³ãƒˆ
                if status_label == 'âœ… OK':
                    ok_count += 1
                else:
                    fail_count += 1
                    # FAILã®å ´åˆã¯ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’è¨˜éŒ²
                    status = data_item.get('status', 'Unknown')
                    fail_statuses.append(status)
            
            print(f"âœ… {input_json_file} ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ ({len(data_list)} ä»¶)")
                
        except FileNotFoundError:
            print(f"è­¦å‘Š: '{input_json_file}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
        except json.JSONDecodeError:
            print(f"ã‚¨ãƒ©ãƒ¼: {input_json_file} ã®JSONãƒ‘ãƒ¼ã‚¹ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

    if not all_markdown_reports:
        print("ã‚¨ãƒ©ãƒ¼: æœ‰åŠ¹ãªãƒ¬ãƒãƒ¼ãƒˆãŒç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")
        exit()

    # ã‚µãƒãƒªãƒ¼ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ä½œæˆ
    summary_lines = []
    summary_lines.append("# ğŸ” SymNet è§£æã‚µãƒãƒªãƒ¼\n")
    summary_lines.append(f"**ç·æ•°**: {ok_count + fail_count} ä»¶")
    summary_lines.append(f"- âœ… **OK**: {ok_count} ä»¶")
    summary_lines.append(f"- âŒ **FAIL**: {fail_count} ä»¶\n")
    
    if fail_count > 0:
        summary_lines.append("## âŒ FAILã®è©³ç´°\n")
        for i, status in enumerate(fail_statuses, 1):
            # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’æ•´å½¢ï¼ˆæœ€åˆã®parserã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½¿ç”¨ï¼‰
            formatted_status = all_markdown_reports[0][0]  # ãƒ€ãƒŸãƒ¼
            # æ–°ã—ã„ãƒ€ãƒŸãƒ¼ãƒ‘ãƒ¼ã‚µãƒ¼ã‚’ä½œæˆã—ã¦ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’æ•´å½¢
            dummy_parser = SymNetParser({'memory': {'tags': []}, 'status': status, 'port_trace': [], 'instruction_trace': []})
            formatted_status = dummy_parser._translate_string(status)
            
            summary_lines.append(f"### FAIL {i}")
            summary_lines.append("```")
            summary_lines.append(formatted_status)
            summary_lines.append("```\n")
    
    summary = "\n".join(summary_lines)

    # ãƒ¬ãƒãƒ¼ãƒˆç•ªå·ã‚’ä»˜ä¸
    total = len(all_markdown_reports)
    formatted_reports = []
    for i in range(total):
        markdown_output, status_label = all_markdown_reports[i]
        report_title = f"# SymNet è§£æãƒ¬ãƒãƒ¼ãƒˆ ({i + 1} / {total}) {status_label}"
        markdown_output = markdown_output.replace(
            "# SymNet è§£æãƒ¬ãƒãƒ¼ãƒˆ", 
            report_title
        )
        formatted_reports.append(markdown_output)

    # çµæœã‚’æ›¸ãå‡ºã—ï¼ˆã‚µãƒãƒªãƒ¼ã‚’å…ˆé ­ã«è¿½åŠ ï¼‰
    output_markdown_file = 'symnet_report.md'
    with open(output_markdown_file, 'w', encoding='utf-8') as f:
        f.write(summary)
        f.write("\n---\n<br/>\n---\n\n")
        f.write("\n\n---\n<br/>\n---\n\n".join(formatted_reports))
        
    print(f"âœ… åˆè¨ˆ {total} ä»¶ã®ãƒ¬ãƒãƒ¼ãƒˆç”ŸæˆãŒå®Œäº†ã—ã¾ã—ãŸ: {output_markdown_file}")